---
title: "p8105_hw6_sl5685"
author: "Shumei Liu"
date: "2024-12-02"
output: github_document
---

```{r}
library(tidyverse)
library(modelr)
library(broom)
library(rnoaa)
library(purrr)
```

## Problem 1

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())

head(weather_df)
```

```{r}
# Fit linear regression model
lm_model = lm(tmax ~ tmin, data = weather_df)

summary(lm_model)
```

```{r}
n_boot = 5000
set.seed(123)
```

```{r}
# Run Bootstrap Procedure
bootstrap_results = replicate(n_boot, {
  boot_sample = weather_df %>% sample_frac(replace = TRUE)
  fit = lm(tmax ~ tmin, data = boot_sample)
  r_squared = glance(fit)$r.squared
  coefs = tidy(fit)$estimate
  log_beta0_beta1 = log(coefs[1] * coefs[2])
  c(r_squared, log_beta0_beta1)
})

bootstrap_df = as.data.frame(t(bootstrap_results))
colnames(bootstrap_df) = c("r_squared", "log_beta0_beta1")
```

```{r}
# Calculate the 95% confidence interval for R-squared
ci_r_squared = quantile(bootstrap_df$r_squared, probs = c(0.025, 0.975))

ci_r_squared

# Calculate the 95% confidence interval for log(beta0 * beta1)
ci_log_beta0_beta1 = quantile(bootstrap_df$log_beta0_beta1, probs = c(0.025, 0.975))

ci_log_beta0_beta1
```

## Problem 2

```{r}
# Import data
homicide_data = read_csv("./data/homicide-data.csv")
```

```{r}
# Create city_state variable and filter the dataset
homicide_data = homicide_data |>
  mutate(city_state = paste(city, state, sep = ", ")) |>
  filter(!city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL")) |>
  filter(victim_race %in% c("White", "Black")) |>
  mutate(victim_age = as.numeric(victim_age))
```

```{r}
# Filter data for Baltimore, MD
baltimore_data = homicide_data |>
  filter(city_state == "Baltimore, MD")

# Fit logistic regression model for Baltimore, MD
model_baltimore = glm(disposition == "Closed by arrest" ~ victim_age + victim_sex + victim_race, 
                       data = baltimore_data, family = "binomial")

# Tidy the model output and extract odds ratio for male victims
tidy_baltimore = tidy(model_baltimore, exponentiate = TRUE, conf.int = TRUE)

# Extract odds ratio for male vs female victims
odds_ratio_sex = tidy_baltimore |>
  filter(term == "victim_sexMale")
odds_ratio_sex
```

```{r}
# Fit logistic regression model for each city in the dataset and extract adjusted odds ratios
city_models = homicide_data |>
  group_by(city_state) |>
  nest() |>
  mutate(model = 
           map(data, ~ glm(disposition == "Closed by arrest" ~ 
                             victim_age + victim_sex + victim_race, 
                           data = ., family = "binomial")),
         tidy_model = map(model, tidy, exponentiate = TRUE, conf.int = TRUE)) |>
  unnest(tidy_model) |>
  filter(term == "victim_sexMale") |>
  select(city_state, estimate, conf.low, conf.high)
```

```{r}
# Plot odds ratios and confidence intervals
ggplot(city_models, aes(x = reorder(city_state, estimate), y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  coord_flip() +
  labs(title = "Adjusted Odds Ratios for Solving Homicides (Male vs Female Victims)",
       x = "City", y = "Odds Ratio (Male vs Female)")
```

The plot organizes cities by the estimated odds ratio (OR) of solving homicides for male versus female victims. Cities like Albuquerque, NM, and Stockton, CA, show higher ORs, indicating potentially higher likelihoods of solving homicides involving male victims. Many cities, however, have ORs close to 1, suggesting no significant gender difference, while wide confidence intervals in several cities reflect uncertainty in the estimates.

## Problem 3

```{r}
birthweight = read_csv("./data/birthweight.csv")
```

