---
title: "p8105_hw6_sl5685"
author: "Shumei Liu"
date: "2024-12-02"
output: github_document
---

```{r}
library(tidyverse)
library(modelr)
library(broom)
library(rnoaa)
library(purrr)
```

## Problem 1

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())

head(weather_df)
```

```{r}
# Fit linear regression model
lm_model = lm(tmax ~ tmin, data = weather_df)

summary(lm_model)
```

```{r}
n_boot = 5000
set.seed(123)
```

```{r}
# Run Bootstrap Procedure
bootstrap_results = replicate(n_boot, {
  boot_sample = weather_df %>% sample_frac(replace = TRUE)
  fit = lm(tmax ~ tmin, data = boot_sample)
  r_squared = glance(fit)$r.squared
  coefs = tidy(fit)$estimate
  log_beta0_beta1 = log(coefs[1] * coefs[2])
  c(r_squared, log_beta0_beta1)
})

bootstrap_df = as.data.frame(t(bootstrap_results))
colnames(bootstrap_df) = c("r_squared", "log_beta0_beta1")
```

```{r}
# Calculate the 95% confidence interval for R-squared
ci_r_squared = quantile(bootstrap_df$r_squared, probs = c(0.025, 0.975))

ci_r_squared

# Calculate the 95% confidence interval for log(beta0 * beta1)
ci_log_beta0_beta1 = quantile(bootstrap_df$log_beta0_beta1, probs = c(0.025, 0.975))

ci_log_beta0_beta1
```

## Problem 2

```{r}
# Import data
homicide_data = read_csv("./data/homicide-data.csv")
```

```{r}
# Create city_state variable and filter the dataset
homicide_data = homicide_data |>
  mutate(city_state = paste(city, state, sep = ", ")) |>
  filter(!city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL")) |>
  filter(victim_race %in% c("White", "Black")) |>
  mutate(victim_age = as.numeric(victim_age)) |>
  filter(!is.na(victim_age))
```

```{r}
# Filter data for Baltimore, MD
baltimore_data = homicide_data |>
  filter(city_state == "Baltimore, MD")

# Fit logistic regression model for Baltimore, MD
model_baltimore = glm(disposition == "Closed by arrest" ~ victim_age + victim_sex + victim_race, 
                       data = baltimore_data, family = "binomial")

# Tidy the model output and extract odds ratio for male victims
tidy_baltimore = tidy(model_baltimore, exponentiate = TRUE, conf.int = TRUE)

# Extract odds ratio for male vs female victims
odds_ratio_sex = tidy_baltimore |>
  filter(term == "victim_sexMale")
odds_ratio_sex
```

```{r}
# Fit logistic regression model for each city in the dataset and extract adjusted odds ratios
city_models = homicide_data |>
  group_by(city_state) |>
  nest() |>
  mutate(model = 
           map(data, ~ glm(disposition == "Closed by arrest" ~ 
                             victim_age + victim_sex + victim_race, 
                           data = ., family = "binomial")),
         tidy_model = map(model, tidy, exponentiate = TRUE, conf.int = TRUE)) |>
  unnest(tidy_model) |>
  filter(term == "victim_sexMale") |>
  select(city_state, estimate, conf.low, conf.high)
```

```{r}
# Plot odds ratios and confidence intervals
ggplot(city_models, aes(x = reorder(city_state, estimate), y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  coord_flip() +
  labs(title = "Adjusted Odds Ratios for Solving Homicides (Male vs Female Victims)",
       x = "City", y = "Odds Ratio (Male vs Female)")
```

The plot organizes cities by the estimated odds ratio (OR) of solving homicides for male versus female victims. Some cities, like Albuquerque, NM, and Stockton, CA, exhibit higher ORs (greater than 1), suggesting that homicides involving male victims are more likely to be solved compared to female victims. Conversely, cities such as New York, NY, and Baton Rouge, LA, have ORs close to 1, indicating little to no difference in the likelihood of solving homicides between male and female victims. Additionally, there are cities where OR values are less than 1, indicating that homicides involving female victims are more likely to be solved compared to male victims. Wide confidence intervals in some cities suggest high variability or limited sample sizes, making it difficult to draw definitive conclusions about gender differences in these locations.

## Problem 3

```{r}
# Import data
birthweight = read_csv("./data/birthweight.csv")
```

```{r}
# clean the dataset
birthweight = birthweight |>
  mutate(
    babysex = factor(babysex, labels = c("Male", "Female")),
    frace = factor(frace),
    malform = factor(malform, labels = c("Absent", "Present")),
    mrace = factor(mrace)
  )

# Check for missing data
missing_data = colSums(is.na(birthweight))
missing_data

# Remove rows with missing data
birthweight = birthweight |> drop_na()
```

```{r}
# Hypothesized Model for Birthweight
model = lm(bwt ~ bhead + blength + gaweeks + momage + ppwt + wtgain, data = birthweight)
summary(model)

# Cross-Validation
set.seed(123)
cv_data = crossv_mc(birthweight, 100)

# Apply Model to Cross-Validation Data
cv_data = cv_data |>
  mutate(
    model = map(train, ~ lm(bwt ~ bhead + blength + gaweeks + momage + ppwt + wtgain, data = .x)),
    rmse = map2_dbl(model, test, ~ rmse(.x, .y))
  )

mean_rmse = mean(cv_data$rmse)

# Residual Plot
model_predictions = add_predictions(birthweight, model)
model_residuals = add_residuals(model_predictions, model)

ggplot(model_residuals, aes(x = pred, y = resid)) +
  geom_point(alpha = 0.5) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(
    x = "Predicted Birth Weight",
    y = "Residuals",
    title = "Residual Plot for Hypothesized Birth Weight Model"
  )
```

```{r}
# Monte Carlo Cross-Validation for Model Comparison
set.seed(123)
monte_carlo_splits = crossv_mc(birthweight, n = 10)
```

```{r}
# Fit models to Monte Carlo splits and compute prediction errors
monte_carlo_results = monte_carlo_splits |>
  mutate(
    hypothesis_model = map(train, ~ lm(bwt ~ babysex + bhead + blength + delwt + gaweeks + ppbmi + smoken, data = as.data.frame(.))),
    length_ga_model = map(train, ~ lm(bwt ~ blength + gaweeks, data = as.data.frame(.))),
    interaction_model = map(train, ~ lm(bwt ~ bhead * blength * babysex, data = as.data.frame(.))),
    
    error_hypothesis = map2_dbl(hypothesis_model, test, ~ mean((predict(.x, newdata = as.data.frame(.y)) - as.data.frame(.y)$bwt)^2, na.rm = TRUE)),
    error_length_ga = map2_dbl(length_ga_model, test, ~ mean((predict(.x, newdata = as.data.frame(.y)) - as.data.frame(.y)$bwt)^2, na.rm = TRUE)),
    error_interaction = map2_dbl(interaction_model, test, ~ mean((predict(.x, newdata = as.data.frame(.y)) - as.data.frame(.y)$bwt)^2, na.rm = TRUE))
  )
```

```{r}
# Summarize prediction errors
monte_carlo_errors = monte_carlo_results |>
  summarize(
    hypothesis_mse = mean(error_hypothesis, na.rm = TRUE),
    length_ga_mse = mean(error_length_ga, na.rm = TRUE),
    interaction_mse = mean(error_interaction, na.rm = TRUE)
  )

monte_carlo_errors
```

The Monte Carlo cross-validation results show that the hypothesis model (which includes head circumference, birth length, maternal weight gain, etc.) has a mean squared error (MSE) of 79299, indicating the best predictive performance among the three models. The length_ga model (which uses only birth length and gestational age) has the highest MSE at 112076, suggesting it does not capture enough features to make accurate predictions. The interaction model (which incorporates head circumference, birth length, and sex with interaction terms) has an MSE of 83574, which is higher than the hypothesis model but lower than the length_ga model. This implies that the interaction terms improve prediction accuracy compared to a simpler model but still do not outperform the more comprehensive hypothesis model.
